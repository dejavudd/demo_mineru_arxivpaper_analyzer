"""
ArXiv PDF Downloader and Image Extractor

ç®€åŒ–çš„å·¥å…·ï¼Œæ”¯æŒä»arXivé“¾æ¥ä¸‹è½½PDFå¹¶ä½¿ç”¨MinerUæå–å…¶ä¸­çš„å›¾ç‰‡ã€‚
æ”¯æŒé“¾æ¥æ ¼å¼ï¼š
- https://arxiv.org/abs/XXXX
- https://arxiv.org/pdf/XXXX
"""

import argparse
import os
import re
import shutil
import subprocess
import sys
from typing import Optional

import requests


def parse_arxiv_url(arxiv_link: str) -> Optional[str]:
    """è§£æarXivé“¾æ¥å¹¶è¿”å›PDFä¸‹è½½é“¾æ¥ã€‚
    
    æ”¯æŒä»¥ä¸‹æ ¼å¼çš„é“¾æ¥ï¼š
    - https://arxiv.org/abs/XXXX
    - https://arxiv.org/pdf/XXXX
    - https://arxiv.org/pdf/XXXX.pdf

    Args:
        arxiv_link: arXivé“¾æ¥ï¼ˆabsæˆ–pdfæ ¼å¼ï¼‰

    Returns:
        PDFä¸‹è½½é“¾æ¥ï¼Œå¦‚æœä¸æ˜¯æœ‰æ•ˆçš„arXivé“¾æ¥åˆ™è¿”å›None
    """
    arxiv_link = arxiv_link.strip()
    
    # å¤„ç†absæ ¼å¼é“¾æ¥: https://arxiv.org/abs/XXXX
    abs_match = re.match(r"https?://arxiv\.org/abs/(?P<id>[\w.\-]+)", arxiv_link)
    if abs_match:
        arxiv_id = abs_match.group("id")
        return f"https://arxiv.org/pdf/{arxiv_id}.pdf"
    
    # å¤„ç†pdfæ ¼å¼é“¾æ¥: https://arxiv.org/pdf/XXXX æˆ– https://arxiv.org/pdf/XXXX.pdf
    pdf_match = re.match(r"https?://arxiv\.org/pdf/(?P<id>[\w.\-]+)(?:\.pdf)?", arxiv_link)
    if pdf_match:
        arxiv_id = pdf_match.group("id")
        if arxiv_id.endswith(".pdf"):
            return f"https://arxiv.org/pdf/{arxiv_id}"
        return f"https://arxiv.org/pdf/{arxiv_id}.pdf"
    
    return None


def extract_arxiv_id(arxiv_link: str) -> Optional[str]:
    """ä»arXivé“¾æ¥ä¸­æå–è®ºæ–‡IDã€‚
    
    Args:
        arxiv_link: arXivé“¾æ¥
        
    Returns:
        è®ºæ–‡IDï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å›None
    """
    # ä»absé“¾æ¥æå–
    abs_match = re.match(r"https?://arxiv\.org/abs/(?P<id>[\w.\-]+)", arxiv_link)
    if abs_match:
        return abs_match.group("id")
    
    # ä»pdfé“¾æ¥æå–
    pdf_match = re.match(r"https?://arxiv\.org/pdf/(?P<id>[\w.\-]+)(?:\.pdf)?", arxiv_link)
    if pdf_match:
        arxiv_id = pdf_match.group("id")
        if arxiv_id.endswith(".pdf"):
            return arxiv_id[:-4]  # å»æ‰.pdfåç¼€
        return arxiv_id
    
    return None


def download_file(url: str, dest_path: str) -> None:
    """ä¸‹è½½æ–‡ä»¶åˆ°æœ¬åœ°è·¯å¾„ã€‚

    Args:
        url: è¿œç¨‹æ–‡ä»¶URL
        dest_path: ç›®æ ‡æ–‡ä»¶è·¯å¾„
    """
    os.makedirs(os.path.dirname(dest_path), exist_ok=True)
    with requests.get(url, stream=True, timeout=60) as r:
        r.raise_for_status()
        with open(dest_path, "wb") as f:
            for chunk in r.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)


def extract_images_with_mineru(pdf_path: str, output_dir: str, lang: str = "en") -> tuple[str, str]:
    """ä½¿ç”¨MinerUä»PDFä¸­æå–å›¾ç‰‡å’Œè®ºæ–‡æ ‡é¢˜ã€‚

    Args:
        pdf_path: PDFæ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•ï¼Œä¼šåœ¨æ­¤ç›®å½•ä¸‹åˆ›å»ºå­ç›®å½•
        lang: è¯­è¨€æç¤ºï¼ˆå¦‚'ch', 'en'ï¼‰ï¼Œå¯æé«˜OCRå‡†ç¡®æ€§

    Returns:
        å…ƒç»„ï¼š(å›¾ç‰‡ç›®å½•è·¯å¾„, è®ºæ–‡æ ‡é¢˜)

    Raises:
        RuntimeError: å¦‚æœMinerUæœªå®‰è£…æˆ–CLIè°ƒç”¨å¤±è´¥
    """
    # ç¡®ä¿MinerU CLIå¯ç”¨
    mineru_cmd = "mineru"
    mineru_output = os.path.join(output_dir, "mineru_output")
    os.makedirs(mineru_output, exist_ok=True)
    
    # æ‰§è¡ŒMinerU CLIè§£æPDFï¼ˆæè‡´å›¾ç‰‡è´¨é‡è®¾ç½®ï¼‰
    cmd = [
        mineru_cmd,
        "-p", pdf_path,
        "-o", mineru_output,
        "-m", "auto",
        "--render-dpi", "1200",  # æ¸²æŸ“DPIè®¾ä¸ºæœ€é«˜
        "--image-dpi", "1200",   # å›¾ç‰‡DPIè®¾ä¸ºæœ€é«˜
        "--image-quality", "100",  # å›¾ç‰‡è´¨é‡100%
        "--keep-vector",         # ä¿æŒçŸ¢é‡å›¾å½¢
        "--no-compress",         # ç¦ç”¨å‹ç¼©
    ]
    if lang:
        cmd.extend(["--lang", lang])
    
    try:
        print(f"ğŸ”„ æ­£åœ¨ä½¿ç”¨MinerUæå–å›¾ç‰‡ï¼ˆ1200 DPIæè‡´è´¨é‡æ¨¡å¼ï¼‰...")
        result = subprocess.run(cmd, check=True, capture_output=True, text=True)
        print(f"âœ“ MinerUæè‡´è´¨é‡å¤„ç†å®Œæˆ")
    except FileNotFoundError as exc:
        raise RuntimeError(
            "æœªæ‰¾åˆ°MinerU CLIã€‚è¯·å®‰è£…MinerU (pip install mineru[core]) å¹¶ç¡®ä¿`mineru`å‘½ä»¤å¯ç”¨ã€‚"
        ) from exc
    except subprocess.CalledProcessError as exc:
        print(f"MinerU stderr: {exc.stderr}")
        raise RuntimeError(f"MinerUå¤„ç†å¤±è´¥ {pdf_path}: {exc.stderr}") from exc
    
    # æŸ¥æ‰¾MinerUç”Ÿæˆçš„å›¾ç‰‡ç›®å½•
    pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]
    
    # MinerUå¯èƒ½ä¼šåˆ›å»ºä¸åŒçš„ç›®å½•ç»“æ„ï¼Œå°è¯•å¤šç§å¯èƒ½çš„è·¯å¾„
    possible_paths = [
        os.path.join(mineru_output, pdf_name, "auto", "images"),
        os.path.join(mineru_output, pdf_name, "images"),
        os.path.join(mineru_output, "auto", "images"),
        os.path.join(mineru_output, "images"),
    ]
    
    images_dir = None
    for path in possible_paths:
        if os.path.exists(path):
            images_dir = path
            break
    
    if not images_dir:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡å‡†è·¯å¾„ï¼Œæœç´¢æ•´ä¸ªè¾“å‡ºç›®å½•
        print(f"ğŸ” æœç´¢MinerUè¾“å‡ºç›®å½•: {mineru_output}")
        for root, dirs, files in os.walk(mineru_output):
            if "images" in dirs:
                images_dir = os.path.join(root, "images")
                print(f"âœ“ æ‰¾åˆ°å›¾ç‰‡ç›®å½•: {images_dir}")
                break
    
    if not images_dir or not os.path.exists(images_dir):
        print(f"âš ï¸  æœªæ‰¾åˆ°å›¾ç‰‡ç›®å½•ï¼ŒMinerUå¯èƒ½æ²¡æœ‰æå–åˆ°å›¾ç‰‡")
        # åˆ›å»ºç©ºç›®å½•ä»¥é¿å…é”™è¯¯
        images_dir = os.path.join(output_dir, "images")
        os.makedirs(images_dir, exist_ok=True)
        # ä½¿ç”¨PDFæ–‡ä»¶åä½œä¸ºé»˜è®¤æ ‡é¢˜
        return images_dir, pdf_name
    
    # ç»Ÿè®¡æå–çš„å›¾ç‰‡
    image_files = [f for f in os.listdir(images_dir) 
                   if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.svg'))]
    
    print(f"âœ“ MinerUæå–äº† {len(image_files)} å¼ å›¾ç‰‡åˆ°: {images_dir}")
    
    # å°è¯•ä»MinerUç”Ÿæˆçš„markdownæ–‡ä»¶ä¸­æå–è®ºæ–‡æ ‡é¢˜
    paper_title = extract_title_from_mineru_output(mineru_output, pdf_name)
    
    return images_dir, paper_title


def extract_title_from_mineru_output(mineru_output: str, pdf_name: str) -> str:
    """ä»MinerUè¾“å‡ºçš„markdownæ–‡ä»¶ä¸­æå–è®ºæ–‡æ ‡é¢˜ã€‚
    
    Args:
        mineru_output: MinerUè¾“å‡ºç›®å½•
        pdf_name: PDFæ–‡ä»¶åï¼ˆä¸åŒ…å«æ‰©å±•åï¼‰
        
    Returns:
        è®ºæ–‡æ ‡é¢˜ï¼Œå¦‚æœæå–å¤±è´¥åˆ™è¿”å›PDFæ–‡ä»¶å
    """
    # å°è¯•æŸ¥æ‰¾markdownæ–‡ä»¶çš„å¯èƒ½è·¯å¾„
    possible_md_paths = [
        os.path.join(mineru_output, pdf_name, "auto", f"{pdf_name}.md"),
        os.path.join(mineru_output, pdf_name, f"{pdf_name}.md"),
        os.path.join(mineru_output, "auto", f"{pdf_name}.md"),
        os.path.join(mineru_output, f"{pdf_name}.md"),
    ]
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡å‡†è·¯å¾„ï¼Œæœç´¢æ‰€æœ‰.mdæ–‡ä»¶
    md_files = []
    for root, dirs, files in os.walk(mineru_output):
        for file in files:
            if file.endswith('.md'):
                md_files.append(os.path.join(root, file))
    
    # å°†æœç´¢åˆ°çš„mdæ–‡ä»¶æ·»åŠ åˆ°å¯èƒ½è·¯å¾„ä¸­
    possible_md_paths.extend(md_files)
    
    for md_path in possible_md_paths:
        if os.path.exists(md_path):
            try:
                with open(md_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                title = extract_title_from_markdown(content)
                if title and title.strip():
                    print(f"âœ“ æå–åˆ°è®ºæ–‡æ ‡é¢˜: {title}")
                    return sanitize_filename(title.strip())
                    
                print(f"âš ï¸  æå–è®ºæ–‡æ ‡é¢˜å¤±è´¥ {md_path}: {e}")
                continue
            except Exception as e:
                print(f"âš ï¸  è¯»å–markdownæ–‡ä»¶å¤±è´¥ {md_path}: {e}")
                continue
    
    print(f"âš ï¸  æ— æ³•æå–è®ºæ–‡æ ‡é¢˜ï¼Œä½¿ç”¨PDFæ–‡ä»¶å: {pdf_name}")
    return pdf_name


def extract_title_from_markdown(content: str) -> str:
    """ä»markdownå†…å®¹ä¸­æå–è®ºæ–‡æ ‡é¢˜ã€‚
    
    Args:
        content: markdownæ–‡ä»¶å†…å®¹
        
    Returns:
        æå–åˆ°çš„æ ‡é¢˜ï¼Œå¦‚æœæå–å¤±è´¥åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    lines = content.split('\n')
    
    # æ–¹æ³•1: æŸ¥æ‰¾ç¬¬ä¸€ä¸ªä¸€çº§æ ‡é¢˜
    for line in lines[:50]:  # åªåœ¨å‰50è¡Œä¸­æŸ¥æ‰¾
        line = line.strip()
        if line.startswith('# ') and len(line) > 2:
            title = line[2:].strip()
            # è¿‡æ»¤æ‰ä¸€äº›å¸¸è§çš„éæ ‡é¢˜å†…å®¹
            if not any(skip in title.lower() for skip in ['abstract', 'introduction', 'content', 'table', 'figure']):
                if len(title) > 10 and len(title) < 200:  # åˆç†çš„æ ‡é¢˜é•¿åº¦
                    return title
    
    # æ–¹æ³•2: æŸ¥æ‰¾æ¨¡å¼åŒ¹é…çš„æ ‡é¢˜è¡Œï¼ˆé€šå¸¸è®ºæ–‡æ ‡é¢˜ä¼šåœ¨å‰å‡ è¡Œï¼Œä¸”è¾ƒé•¿ï¼‰
    for i, line in enumerate(lines[:20]):
        line = line.strip()
        if line and not line.startswith('#') and not line.startswith('*'):
            # æ£€æŸ¥æ˜¯å¦åƒæ ‡é¢˜ï¼ˆé•¿åº¦é€‚ä¸­ï¼ŒåŒ…å«å¤§å†™å­—æ¯ç­‰ï¼‰
            if (20 < len(line) < 200 and 
                any(c.isupper() for c in line) and 
                ':' not in line[:20] and  # æ’é™¤ç±»ä¼¼ "Abstract:" çš„è¡Œ
                line.count('.') < 3):  # æ’é™¤å¥å­
                return line
    
    # æ–¹æ³•3: æŸ¥æ‰¾ç²—ä½“æ ‡è®°çš„æ–‡æœ¬ï¼ˆå¯èƒ½æ˜¯æ ‡é¢˜ï¼‰
    import re
    bold_pattern = r'\*\*(.*?)\*\*'
    bold_matches = re.findall(bold_pattern, content[:2000])  # åœ¨å‰2000å­—ç¬¦ä¸­æŸ¥æ‰¾
    for match in bold_matches:
        if 20 < len(match) < 200 and not any(skip in match.lower() for skip in ['abstract', 'figure', 'table']):
            return match
    
    return ""


def enhance_image_quality(src_path: str, dst_path: str) -> Optional[str]:
    """ä½¿ç”¨å¤šç§æ–¹æ³•å¢å¼ºå›¾ç‰‡è´¨é‡ã€‚
    
    Args:
        src_path: æºå›¾ç‰‡è·¯å¾„
        dst_path: ç›®æ ‡å›¾ç‰‡è·¯å¾„
        
    Returns:
        å¢å¼ºåçš„å›¾ç‰‡è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    try:
        # å°è¯•å¯¼å…¥PILå’ŒOpenCVè¿›è¡Œå›¾ç‰‡å¤„ç†
        try:
            from PIL import Image, ImageEnhance, ImageFilter
            import cv2
            import numpy as np
            has_cv2 = True
        except ImportError:
            from PIL import Image, ImageEnhance, ImageFilter
            has_cv2 = False
        
        # æ‰“å¼€å›¾ç‰‡
        with Image.open(src_path) as img:
            # è½¬æ¢ä¸ºRGBæ¨¡å¼ï¼ˆå¦‚æœä¸æ˜¯çš„è¯ï¼‰
            if img.mode != 'RGB':
                img = img.convert('RGB')
            
            width, height = img.size
            original_size = width * height
            
            # 1. æ™ºèƒ½ä¸Šé‡‡æ ·
            if original_size < 1000000:  # å°äº1MPçš„å›¾ç‰‡
                if has_cv2:
                    # ä½¿ç”¨OpenCVçš„EDSRè¶…åˆ†è¾¨ç‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    enhanced_img = apply_cv2_super_resolution(img)
                    if enhanced_img:
                        img = enhanced_img
                        print(f"    ğŸ§  AIè¶…åˆ†è¾¨ç‡: {width}x{height} â†’ {img.size[0]}x{img.size[1]}")
                    else:
                        # å›é€€åˆ°LANCZOSä¸Šé‡‡æ ·
                        scale = min(4, int(np.sqrt(2000000 / original_size)))  # åŠ¨æ€è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
                        new_size = (width * scale, height * scale)
                        img = img.resize(new_size, Image.Resampling.LANCZOS)
                        print(f"    ğŸ“ˆ é«˜è´¨é‡ä¸Šé‡‡æ ·: {width}x{height} â†’ {new_size[0]}x{new_size[1]}")
                else:
                    # æ ‡å‡†LANCZOSä¸Šé‡‡æ ·
                    scale = min(3, int(np.sqrt(1500000 / original_size)))
                    new_size = (width * scale, height * scale)
                    img = img.resize(new_size, Image.Resampling.LANCZOS)
                    print(f"    ğŸ“ˆ æ ‡å‡†ä¸Šé‡‡æ ·: {width}x{height} â†’ {new_size[0]}x{new_size[1]}")
            
            # 2. å›¾ç‰‡å¢å¼ºå¤„ç†
            img = apply_image_enhancement(img)
            
            # ä¿å­˜ä¸ºé«˜è´¨é‡PNG
            base_name = os.path.splitext(dst_path)[0]
            enhanced_path = f"{base_name}_enhanced.png"
            img.save(enhanced_path, 'PNG', optimize=False, compress_level=0)
            
            return enhanced_path
            
    except Exception as e:
        print(f"    âš ï¸  å›¾ç‰‡å¢å¼ºå¤±è´¥: {e}")
        # å¤±è´¥æ—¶ç›´æ¥å¤åˆ¶åŸæ–‡ä»¶
        shutil.copy2(src_path, dst_path)
        return dst_path


def apply_cv2_super_resolution(pil_img):
    """ä½¿ç”¨OpenCVè¿›è¡ŒAIè¶…åˆ†è¾¨ç‡å¤„ç†ã€‚"""
    try:
        import cv2
        import numpy as np
        from PIL import Image
        
        # å°†PILå›¾ç‰‡è½¬æ¢ä¸ºOpenCVæ ¼å¼
        img_array = np.array(pil_img)
        img_cv2 = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
        
        # ä½¿ç”¨OpenCVçš„é«˜è´¨é‡ä¸Šé‡‡æ ·ç®—æ³•
        height, width = img_cv2.shape[:2]
        upscaled = cv2.resize(img_cv2, (width * 2, height * 2), interpolation=cv2.INTER_CUBIC)
        
        # åº”ç”¨é”åŒ–æ»¤æ³¢å™¨
        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
        sharpened = cv2.filter2D(upscaled, -1, kernel)
        
        # è½¬æ¢å›PILæ ¼å¼
        result_rgb = cv2.cvtColor(sharpened, cv2.COLOR_BGR2RGB)
        result_pil = Image.fromarray(result_rgb)
        
        return result_pil
        
    except Exception as e:
        print(f"    âš ï¸  OpenCVå¤„ç†å¤±è´¥: {e}")
        return None


def apply_image_enhancement(img):
    """åº”ç”¨å›¾ç‰‡å¢å¼ºå¤„ç†ã€‚"""
    try:
        from PIL import ImageEnhance, ImageFilter
        
        # 1. è½»å¾®é”åŒ–
        enhancer = ImageEnhance.Sharpness(img)
        img = enhancer.enhance(1.3)
        
        # 2. å¯¹æ¯”åº¦å¢å¼º
        enhancer = ImageEnhance.Contrast(img)
        img = enhancer.enhance(1.15)
        
        # 3. è‰²å½©é¥±å’Œåº¦å¾®è°ƒ
        enhancer = ImageEnhance.Color(img)
        img = enhancer.enhance(1.05)
        
        # 4. è½»å¾®çš„é™å™ªï¼ˆä½¿ç”¨æ›´æ¸©å’Œçš„æ»¤é•œï¼‰
        img = img.filter(ImageFilter.SMOOTH)
        
        print(f"    âœ¨ å›¾ç‰‡å¢å¼ºå®Œæˆï¼šé”åŒ–+å¯¹æ¯”åº¦+é™å™ª")
        
        return img
        
    except Exception as e:
        print(f"    âš ï¸  å›¾ç‰‡å¢å¼ºå¤„ç†å¤±è´¥: {e}")
        return img


def sanitize_filename(name: str) -> str:
    """å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºå®‰å…¨çš„æ–‡ä»¶åã€‚"""
    return re.sub(r"[^\w\-\.]+", "_", name).strip("._")


def copy_images_to_output(source_images_dir: str, output_dir: str, paper_title: str) -> tuple[int, str]:
    """å°†æå–çš„å›¾ç‰‡å¤åˆ¶åˆ°è¾“å‡ºç›®å½•ã€‚
    
    Args:
        source_images_dir: MinerUæå–çš„å›¾ç‰‡æºç›®å½•
        output_dir: ç›®æ ‡è¾“å‡ºç›®å½•
        paper_title: è®ºæ–‡æ ‡é¢˜ï¼Œç”¨ä½œç›®å½•å
        
    Returns:
        å…ƒç»„ï¼š(å¤åˆ¶çš„å›¾ç‰‡æ•°é‡, è®ºæ–‡è¾“å‡ºç›®å½•è·¯å¾„)
    """
    # åˆ›å»ºä»¥è®ºæ–‡æ ‡é¢˜å‘½åçš„è¾“å‡ºç›®å½•
    paper_output_dir = os.path.join(output_dir, paper_title)
    os.makedirs(paper_output_dir, exist_ok=True)
    
    if not os.path.exists(source_images_dir):
        print(f"âš ï¸  æºå›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {source_images_dir}")
        return 0, paper_output_dir
    
    copied_count = 0
    
    # è¿‡æ»¤å¹¶å¤åˆ¶å›¾ç‰‡
    for image_file in os.listdir(source_images_dir):
        if image_file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.svg')):
            src_path = os.path.join(source_images_dir, image_file)
            dst_path = os.path.join(paper_output_dir, image_file)
            
            # è¿‡æ»¤å¤ªå°çš„å›¾ç‰‡ï¼ˆå¯èƒ½æ˜¯è£…é¥°æ€§å›¾ç‰‡ï¼‰
            try:
                file_size = os.path.getsize(src_path)
                if file_size < 5000:  # å°äº5KBçš„å›¾ç‰‡è·³è¿‡
                    continue
                
                # å°è¯•è¿›è¡Œå›¾ç‰‡è´¨é‡å¢å¼º
                enhanced_path = enhance_image_quality(src_path, dst_path)
                if enhanced_path:
                    final_size = os.path.getsize(enhanced_path)
                    copied_count += 1
                    print(f"âœ“ å¤åˆ¶å¹¶å¢å¼ºå›¾ç‰‡: {image_file} ({file_size//1024}KB â†’ {final_size//1024}KB)")
                else:
                    shutil.copy2(src_path, dst_path)
                    copied_count += 1
                    print(f"âœ“ å¤åˆ¶å›¾ç‰‡: {image_file} ({file_size//1024}KB)")
                
            except Exception as e:
                print(f"âš ï¸  å¤åˆ¶å›¾ç‰‡å¤±è´¥ {image_file}: {e}")
    
    print(f"âœ“ å…±å¤åˆ¶ {copied_count} å¼ å›¾ç‰‡åˆ°: {paper_output_dir}")
    return copied_count, paper_output_dir





def process_arxiv_paper(arxiv_url: str, output_dir: str = "output") -> bool:
    """å¤„ç†å•ä¸ªarXivè®ºæ–‡ï¼šä¸‹è½½PDFå¹¶æå–å›¾ç‰‡ã€‚

    Args:
        arxiv_url: arXivè®ºæ–‡é“¾æ¥ï¼ˆæ”¯æŒabså’Œpdfæ ¼å¼ï¼‰
        output_dir: è¾“å‡ºç›®å½•

    Returns:
        å¤„ç†æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
    """
    try:
        print(f"ğŸ“¥ å¼€å§‹å¤„ç†arXivè®ºæ–‡: {arxiv_url}")
        
        # è§£æarXivé“¾æ¥è·å–PDFä¸‹è½½é“¾æ¥
        pdf_url = parse_arxiv_url(arxiv_url)
        if not pdf_url:
            print(f"âŒ æ— æ•ˆçš„arXivé“¾æ¥: {arxiv_url}")
            return False
        
        # æå–è®ºæ–‡IDä½œä¸ºæ–‡ä»¶å
        paper_id = extract_arxiv_id(arxiv_url)
        if not paper_id:
            print(f"âŒ æ— æ³•ä»é“¾æ¥ä¸­æå–è®ºæ–‡ID: {arxiv_url}")
            return False
        
        print(f"ğŸ“„ è®ºæ–‡ID: {paper_id}")
        print(f"ğŸ“¥ PDFä¸‹è½½é“¾æ¥: {pdf_url}")
        
        # åˆ›å»ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        tmp_dir = os.path.join(output_dir, ".tmp")  # ä¸´æ—¶ç›®å½•è®¾åœ¨outputä¸‹çš„éšè—æ–‡ä»¶å¤¹
        os.makedirs(tmp_dir, exist_ok=True)
        
        # ä¸‹è½½PDF
        safe_paper_id = sanitize_filename(paper_id)
        pdf_path = os.path.join(tmp_dir, f"{safe_paper_id}.pdf")
        
        print(f"â¬‡ï¸ æ­£åœ¨ä¸‹è½½PDF...")
        download_file(pdf_url, pdf_path)
        print(f"âœ… PDFä¸‹è½½å®Œæˆ: {pdf_path}")
        
        # ä½¿ç”¨MinerUæå–å›¾ç‰‡å’Œè®ºæ–‡æ ‡é¢˜
        print(f"ğŸ–¼ï¸ æ­£åœ¨ä½¿ç”¨MinerUæå–å›¾ç‰‡å’Œè®ºæ–‡æ ‡é¢˜...")
        images_dir, paper_title = extract_images_with_mineru(pdf_path, tmp_dir)
        
        # å¦‚æœæœªèƒ½æå–åˆ°æ ‡é¢˜ï¼Œä½¿ç”¨è®ºæ–‡IDä½œä¸ºå¤‡ç”¨
        if not paper_title or paper_title == os.path.splitext(os.path.basename(pdf_path))[0]:
            paper_title = safe_paper_id
            print(f"ğŸ“„ ä½¿ç”¨è®ºæ–‡IDä½œä¸ºæ–‡ä»¶å¤¹å: {paper_title}")
        else:
            print(f"ğŸ“„ è®ºæ–‡æ ‡é¢˜: {paper_title}")
        
        # å¤åˆ¶å›¾ç‰‡åˆ°è¾“å‡ºç›®å½•
        print(f"ğŸ“ æ­£åœ¨æ•´ç†è¾“å‡ºæ–‡ä»¶...")
        copied_count, paper_output_dir = copy_images_to_output(images_dir, output_dir, paper_title)
        
        # å¤åˆ¶PDFåˆ°è¾“å‡ºç›®å½•
        output_pdf_path = os.path.join(paper_output_dir, f"{sanitize_filename(paper_title)}.pdf")
        shutil.copy2(pdf_path, output_pdf_path)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            shutil.rmtree(tmp_dir)
            print(f"ğŸ—‘ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {tmp_dir}")
        except Exception as e:
            print(f"âš ï¸  æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
        
        print(f"\nğŸ‰ å¤„ç†å®Œæˆ!")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {paper_output_dir}")
        print(f"ğŸ“„ PDFæ–‡ä»¶: {os.path.basename(output_pdf_path)}")
        print(f"ğŸ–¼ï¸ å›¾ç‰‡æ•°é‡: {copied_count}")
        print(f"ğŸ“ å›¾ç‰‡ä½ç½®: ä¸PDFæ–‡ä»¶åœ¨åŒä¸€ç›®å½•")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        return False


def main() -> None:
    """ä¸»å‡½æ•°ï¼šè§£æå‘½ä»¤è¡Œå‚æ•°å¹¶å¤„ç†arXivè®ºæ–‡ã€‚"""
    parser = argparse.ArgumentParser(
        description="ä»arXivé“¾æ¥ä¸‹è½½PDFå¹¶æå–å›¾ç‰‡",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
æ”¯æŒçš„é“¾æ¥æ ¼å¼:
  https://arxiv.org/abs/2412.15289
  https://arxiv.org/pdf/2412.15289
  https://arxiv.org/pdf/2412.15289.pdf

ä½¿ç”¨ç¤ºä¾‹:
  python lrm_paper_analyzer.py https://arxiv.org/abs/2412.15289
  python lrm_paper_analyzer.py --url https://arxiv.org/pdf/2412.15289 --output papers
        """
    )
    
    parser.add_argument(
        "url",
        nargs="?",
        help="arXivè®ºæ–‡é“¾æ¥ï¼ˆabsæˆ–pdfæ ¼å¼ï¼‰"
    )
    
    parser.add_argument(
        "--url", 
        dest="arxiv_url",
        help="arXivè®ºæ–‡é“¾æ¥ï¼ˆä¸ä½ç½®å‚æ•°äºŒé€‰ä¸€ï¼‰"
    )
    
    parser.add_argument(
        "--output",
        default="output",
        help="è¾“å‡ºç›®å½• (é»˜è®¤: output)"
    )
    
    args = parser.parse_args()
    
    # è·å–arXivé“¾æ¥
    arxiv_url = args.url or args.arxiv_url
    if not arxiv_url:
        print("âŒ è¯·æä¾›arXivè®ºæ–‡é“¾æ¥")
        print("ä½¿ç”¨ç¤ºä¾‹: python lrm_paper_analyzer.py https://arxiv.org/abs/2412.15289")
        print("æˆ–è€…: python lrm_paper_analyzer.py --url https://arxiv.org/abs/2412.15289")
        sys.exit(1)
    
    # å¤„ç†è®ºæ–‡
    success = process_arxiv_paper(arxiv_url, args.output)
    
    if success:
        print(f"\nâœ… å¤„ç†æˆåŠŸ! ç»“æœä¿å­˜åœ¨: {args.output}")
        sys.exit(0)
    else:
        print(f"\nâŒ å¤„ç†å¤±è´¥!")
        sys.exit(1)


if __name__ == "__main__":
    main()